
import streamlit as st
import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModel
import pandas as pd

# í•„ìˆ˜ ì„œë²„ ì„¤ì •
st.set_page_config(
    page_title="ì˜ë£Œ ì§„ë£Œê³¼ ì¶”ì²œ ì‹œìŠ¤í…œ",
    page_icon="ğŸ¥",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# ë³´ì•ˆ ë° ì ‘ê·¼ ì„¤ì •
import streamlit.components.v1 as components
components.html("""
    <script>
        if (window.top != window.self) {
            window.top.location = window.self.location;
        }
    </script>
""", height=0)

# MedicalBertClassifier í´ë˜ìŠ¤ ì •ì˜
class MedicalBertClassifier(nn.Module):
    def __init__(self, num_classes, dropout_rate=0.3):
        super().__init__()
        self.bert = AutoModel.from_pretrained("madatnlp/km-bert")
        self.dropout = nn.Dropout(dropout_rate)
        hidden_size = self.bert.config.hidden_size
        self.classifier = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_size // 2, num_classes)
        )

    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output
        pooled_output = self.dropout(pooled_output)
        return self.classifier(pooled_output)

# ì˜ˆì¸¡ì„ ìœ„í•œ í´ë˜ìŠ¤ ì •ì˜
class MedicalDepartmentPredictor:
    def __init__(self, model_path, device='cpu'):
        self.device = device
        self.tokenizer = AutoTokenizer.from_pretrained("madatnlp/km-bert")
        
        # ì§„ë£Œê³¼ ë§¤í•‘ ìƒì„±
        df = pd.read_csv("./data/final_df.csv", encoding="utf-8")

        # ì§„ë£Œê³¼ëª©ì½”ë“œì™€ ì‹¤ì œ ì§„ë£Œê³¼ ë§¤í•‘
        dept_mapping = {
            0: 'ì¼ë°˜ì˜', 1: 'ë‚´ê³¼', 2: 'ì‹ ê²½ê³¼', 3: 'ì •ì‹ ê³¼', 4: 'ì™¸ê³¼', 5: 'ì •í˜•ì™¸ê³¼', 6: 'ì‹ ê²½ì™¸ê³¼',
            7: 'í‰ë¶€ì™¸ê³¼', 8: 'ì„±í˜•ì™¸ê³¼', 9: 'ë§ˆì·¨í†µì¦ì˜í•™ê³¼', 10: 'ì‚°ë¶€ì¸ê³¼', 11: 'ì†Œì•„ì²­ì†Œë…„ê³¼',
            12: 'ì•ˆê³¼', 13: 'ì´ë¹„ì¸í›„ê³¼', 14: 'í”¼ë¶€ê³¼', 15: 'ë¹„ë‡¨ê¸°ê³¼', 16: 'ì˜ìƒì˜í•™ê³¼',
            17: 'ë°©ì‚¬ì„  ì¢…ì–‘í•™ê³¼', 18: 'ë³‘ë¦¬ê³¼', 19: 'ì§„ë‹¨ê²€ì‚¬ì˜í•™ê³¼', 20: 'ê²°í•µê³¼',
            21: 'ì¬í™œì˜í•™ê³¼', 22: 'í•µì˜í•™ê³¼', 23: 'ê°€ì •ì˜í•™ê³¼', 24: 'ì‘ê¸‰ì˜í•™ê³¼',
            25: 'ì‚°ì—…ì˜í•™ê³¼', 26: 'ì˜ˆë°©ì˜í•™ê³¼', 50: 'êµ¬ê°•ì•…ì•ˆë©´ì™¸ê³¼', 51: 'ì¹˜ê³¼ë³´ì² ê³¼',
            52: 'ì¹˜ê³¼êµì •ê³¼', 53: 'ì†Œì•„ì¹˜ê³¼', 54: 'ì¹˜ì£¼ê³¼', 55: 'ì¹˜ê³¼ë³´ì¡´ê³¼',
            56: 'êµ¬ê°•ë‚´ê³¼', 57: 'êµ¬ê°•ì•…ì•ˆë©´ë°©ì‚¬ì„ ê³¼', 58: 'êµ¬ê°•ë³‘ë¦¬ê³¼',
            59: 'ì˜ˆë°©ì¹˜ê³¼', 80: 'í•œë°©ë‚´ê³¼', 81: 'í•œë°©ë¶€ì¸ê³¼',
            82: 'í•œë°©ì†Œì•„ê³¼', 83: 'í•œë°©ì•ˆÂ·ì´ë¹„ì¸í›„Â·í”¼ë¶€ ê³¼',
            84: 'í•œë°©ì‹ ê²½ì •ì‹  ê³¼', 85: 'ì¹¨êµ¬ ê³¼',
            86: 'í•œë°©ì¬í™œì˜í•™ ê³¼',87:'ì‚¬ìƒì²´ì§ˆ ê³¼',
            88:'í•œë°©ì‘ê¸‰ ê³¼','ZZ':'Nan'
        }
        unique_departments = sorted(df['ì§„ë£Œê³¼ëª©ì½”ë“œ'].unique())
        self.idx_to_dept = {str(idx): dept_mapping.get(dept, dept) for idx, dept in enumerate(unique_departments)}
        num_classes = len(self.idx_to_dept)
        
        self.model = MedicalBertClassifier(num_classes=num_classes).to(device)
        self.model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))
        self.model.eval()

    def clean_text(self, text):
        import re
        text = re.sub(r'[^ê°€-í£a-zA-Z0-9.,\s]', ' ', str(text))
        text = re.sub(r'\s+', ' ', text).strip()
        text = re.sub(r'\.+', '.', text)
        return text

    def predict(self, text):
        cleaned_text = self.clean_text(text)
        inputs = self.tokenizer(
            cleaned_text,
            max_length=512,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )

        with torch.no_grad():
            input_ids = inputs['input_ids'].to(self.device)
            attention_mask = inputs['attention_mask'].to(self.device)
            outputs = self.model(input_ids, attention_mask)
            probs = F.softmax(outputs, dim=1)

        pred_idx = torch.argmax(probs, dim=1).item()
        pred_dept = self.idx_to_dept[str(pred_idx)]
        confidence = probs[0][pred_idx].item()
        
        return pred_dept, confidence


# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown("""
    <style>
    .main-title {
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 2rem;
        color: #1E88E5;
    }
    .result-box {
        background-color: #F8F9FA;
        padding: 2rem;
        border-radius: 10px;
        margin-top: 2rem;
        border: 1px solid #E0E0E0;
    }
    </style>
    """, unsafe_allow_html=True)

# ì•± ì œëª©
st.markdown('<p class="main-title">ì˜ë£Œ ì§„ë£Œê³¼ ì¶”ì²œ ì‹œìŠ¤í…œ ğŸ¥</p>', unsafe_allow_html=True)

# ëª¨ë¸ ë¡œë“œ
@st.cache_resource
def load_predictor():
    return MedicalDepartmentPredictor(model_path='./data/best_model.pt', device='mps')

try:
    predictor = load_predictor()

    # ì‚¬ìš©ì ì…ë ¥
    st.markdown("### ì–´ë””ê°€ ì–´ë–»ê²Œ ì•„í”„ì‹ ê°€ìš”? êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ì£¼ì„¸ìš”.")
    user_input = st.text_area(
        label="ì¦ìƒì„ ì…ë ¥í•´ì£¼ì„¸ìš”",
        height=150,
        placeholder="ì˜ˆì‹œ: ê¸°ì¹¨ì´ ì‹¬í•˜ê³  ê°€ë˜ê°€ ìˆìœ¼ë©°, í˜¸í¡ì´ ê³¤ë€í•œ ì¦ìƒì´ ìˆìŠµë‹ˆë‹¤..."
    )

    # ì˜ˆì¸¡ ì‹¤í–‰ ë¶€ë¶„
    if st.button("ì¦ìƒ ë¶„ì„í•˜ê¸°", type="primary"):
        if user_input:
            with st.spinner('ì¦ìƒì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                pred_dept, confidence = predictor.predict(user_input)

            st.markdown(f"""
            <div class="result-box">
                <p style='font-size: 1.2rem; color: #2E7D32;'>
                    ê·€í•˜ì˜ ì¦ìƒì„ ë¶„ì„í•´ë³´ë‹ˆ <b>{pred_dept}</b>ì— ë°©ë¬¸í•´ë³´ì‹œëŠ” ê±¸ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.
                </p>
                <p style='font-size: 0.9rem; color: #757575;'>
                    ì¶”ì²œ ì‹ ë¢°ë„: {confidence*100:.1f}%
                </p>
            </div>
            """, unsafe_allow_html=True)

            st.info("â€» ë³¸ ì¶”ì²œì€ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤. ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•´ì„œëŠ” ë°˜ë“œì‹œ ì˜ë£Œì§„ê³¼ì˜ ìƒë‹´ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            st.warning("ì¦ìƒì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

except Exception as e:
    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    st.info("ëª¨ë¸ íŒŒì¼ê³¼ ë°ì´í„° íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
